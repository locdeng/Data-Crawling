# Company Data Crawler (JobKorea, JobPlanet, Naver API)

This project collects and processes company information from three sources:  
- **JobKorea** (using BeautifulSoup)  
- **JobPlanet** (using Selenium)  
- **Naver Search API** (using requests)

The dataset includes **500+ South Korean companies name**

---

## ğŸ“Œ Features

âœ… Scrape company info (name, industry, capital, sale, established day, and CEO) from **JobKorea**  
âœ… Extract employee reviews and ratings from **JobPlanet**  
âœ… Validate and enrich company names using **Naver Open API**  
âœ… Save final dataset to `.csv`   
âœ… Headless browser automation using Selenium  
âœ… Clean and efficient modular code  

---

## ğŸ–¥ï¸ Tech Stack

| Tool        | Purpose                              |
|-------------|--------------------------------------|
| `Python 3.x`| Programming language                 |
| `BeautifulSoup` | HTML parsing (JobKorea)          |
| `Selenium`  | Dynamic content automation (JobPlanet)|
| `requests`  | API communication (Naver API)        |
| `pandas`    | Data processing and exporting        |
| `openpyxl`  | Excel file handling                  |


---

## ğŸ§± Project Structure
company-crawler/

â”œâ”€â”€ jobkorea_data_crawling_edited.py # Crawls JobKorea using BeautifulSoup

â”œâ”€â”€ Crawling_Jobplanet_edited.py # Automates JobPlanet with Selenium

â”œâ”€â”€ craling_news_naver_edited.py # Queries Naver Open API

â”œâ”€â”€ companies.csv # expected a output dataset file

â”œâ”€â”€ requirements.txt # Python dependencies

â””â”€â”€ README.md # Project documentation

